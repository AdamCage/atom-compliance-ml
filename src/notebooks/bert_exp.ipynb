{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "abs_path = Path().resolve()\n",
    "sys.path.append(str(abs_path.parent / \"modules\"))\n",
    "\n",
    "from files_funcs import *\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "main_dir = abs_path.parent.parent\n",
    "\n",
    "config_path = abs_path.parent.parent / \"config\" / \"config.yaml\"\n",
    "config = load_yaml(config_path)\n",
    "\n",
    "data_dir = main_dir / \"data\" / \"ds\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = (\n",
    "    BertModel\n",
    "    .from_pretrained(config[\"bert\"], output_hidden_states=True)\n",
    "    .to(DEVICE)\n",
    ")\n",
    "tokenizer = BertTokenizer.from_pretrained(config[\"bert\"])\n",
    "\n",
    "display(bert_model)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_vectors(df, column, model, tokenizer, device, verbose=True, verbose_interval=100):\n",
    "    df = df.copy()\n",
    "    model = model.to(device)\n",
    "    if verbose:\n",
    "        total_images = df.shape[0]\n",
    "        _ = 0\n",
    "\n",
    "    vectors = []\n",
    "    for index, row in df.reset_index(drop=True).iterrows():\n",
    "        index += 1\n",
    "        text = row[column][:1800]\n",
    "        input_ids = torch.tensor(\n",
    "            [tokenizer.encode(text, add_special_tokens=True)]).to(device)\n",
    "        with torch.no_grad():\n",
    "            model_output = model(input_ids)\n",
    "        vectors.append(\n",
    "            model_output.last_hidden_state.mean(dim=1).squeeze().tolist())\n",
    "\n",
    "        if verbose and (index % verbose_interval == 0 or index == total_images - 1):\n",
    "            print(f\"{_}. Processed text {index}/{total_images}.\")\n",
    "            _ += 1\n",
    "\n",
    "    assert all(len(vector) == len(vectors[0]) for vector in vectors), \"Text vectors have different dimensions\"\n",
    "\n",
    "    vectors_np = np.array(vectors)\n",
    "    df[[f\"text_vector_el{x}\"\n",
    "        for x in range(len(vectors_np[0]))]] = vectors_np\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'case_name', 'full_uc_text', 'full_ssts_text',\n",
       "       'alternative_scenario', 'main_scenario', 'goal', 'other',\n",
       "       'preconditions', 'postconditions', 'differences', 'description',\n",
       "       'complience_level', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv(data_dir / \"ds.unl\", sep=\"|\")\n",
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Processed text 11/12.\n"
     ]
    }
   ],
   "source": [
    "ssts_texts = pd.DataFrame(ds[\"full_ssts_text\"]).fillna(\"EMPTY\")\n",
    "\n",
    "ssts_texts_vectorized = extract_text_vectors(\n",
    "    ssts_texts,\n",
    "    \"full_ssts_text\",\n",
    "    bert_model,\n",
    "    tokenizer,\n",
    "    DEVICE\n",
    ").drop(\"full_ssts_text\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, manhattan_distances, euclidean_distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cosinus_feature(texts: pd.Series, ssts_texts_vectorized: pd.DataFrame) -> pd.DataFrame:\n",
    "    feature = texts.name\n",
    "    vec = extract_text_vectors(\n",
    "        pd.DataFrame(texts).fillna(\"EMPTY\"),\n",
    "        feature,\n",
    "        bert_model,\n",
    "        tokenizer,\n",
    "        DEVICE\n",
    "    ).drop(feature, axis=1)\n",
    "\n",
    "    cosins = cosine_similarity(vec, ssts_texts_vectorized).diagonal()\n",
    "    manh = manhattan_distances(vec, ssts_texts_vectorized).diagonal()\n",
    "    euc = euclidean_distances(vec, ssts_texts_vectorized).diagonal()\n",
    "\n",
    "    return cosins, manh# , euc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Processed text 11/12.\n"
     ]
    }
   ],
   "source": [
    "to_features = [\n",
    "    \"full_uc_text\",\n",
    "    # \"alternative_scenario\",\n",
    "    # \"main_scenario\",\n",
    "    # \"goal\",\n",
    "    # \"other\",\n",
    "    # \"preconditions\",\n",
    "    # \"postconditions\"\n",
    "]\n",
    "for f in to_features:\n",
    "    # ds[f'cos_{f}'], ds[f'man_{f}'], ds[f'euc_{f}'] = create_cosinus_feature(ds[f], ssts_texts_vectorized)\n",
    "    ds[f'cos_{f}'], ds[f'man_{f}'] = create_cosinus_feature(ds[f], ssts_texts_vectorized)\n",
    "    # ds[f'cos_{f}'] = create_cosinus_feature(ds[f], ssts_texts_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_full_uc_text</th>\n",
       "      <th>man_full_uc_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cos_full_uc_text</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.989051</td>\n",
       "      <td>0.622494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man_full_uc_text</th>\n",
       "      <td>-0.989051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.600218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.622494</td>\n",
       "      <td>-0.600218</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cos_full_uc_text  man_full_uc_text    target\n",
       "cos_full_uc_text          1.000000         -0.989051  0.622494\n",
       "man_full_uc_text         -0.989051          1.000000 -0.600218\n",
       "target                    0.622494         -0.600218  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xy = ds[[f for f in ds.columns if f.startswith((\"cos_\", \"man_\", \"euc_\"))] + [\"target\"]]\n",
    "\n",
    "display(Xy.corr())\n",
    "\n",
    "X = Xy.drop(\"target\", axis=1)\n",
    "y = Xy[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.74772893361318)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X.head(100), y.head(100))\n",
    "preds = model.predict(X)\n",
    "mean_squared_error(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3.677595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.654093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3.699339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3.576079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.551161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>3.557618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>3.651002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3.650755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>3.609977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>3.626707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1.087178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>3.658494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target     preds\n",
       "0        3  3.677595\n",
       "1        2  3.654093\n",
       "2        4  3.699339\n",
       "3        5  3.576079\n",
       "4        4  3.551161\n",
       "5        4  3.557618\n",
       "6        4  3.651002\n",
       "7        2  3.650755\n",
       "8        4  3.609977\n",
       "9        4  3.626707\n",
       "10       1  1.087178\n",
       "11       4  3.658494"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy.assign(preds=preds)[[\"target\", \"preds\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import difflib\n",
    "from docx import Document\n",
    "\n",
    "#import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Отображать все столбцы\n",
    "pd.set_option('display.max_rows', None)     # Отображать все строки\n",
    "pd.set_option('display.max_colwidth', None) # Отключить обрезание текста в ячейках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    lines = []  \n",
    "    \n",
    "    for paragraph in doc.paragraphs:\n",
    "        line = paragraph.text.strip()  \n",
    "        if line: \n",
    "            lines.append(f'\"{line}\"')\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def load_files_to_dataframe(file_paths):\n",
    "    uc_data = []  \n",
    "    ssts_data = []  \n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        lines = read_docx(file_path)\n",
    "        \n",
    "        if 'UC' in file_path:\n",
    "            uc_data.append(lines)\n",
    "        else:\n",
    "            ssts_data.append(lines)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'UC': uc_data,\n",
    "        'SSTS': ssts_data\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\HMI\\UC-6583.docx', \n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\HMI\\UC-8604.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\HMI\\UC-8692.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\HMI\\UC-8800.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\HMI\\UC-11467.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\HMI\\UC-25957.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\HMI\\UC-26160.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\HMI\\UC-26161.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\HMI\\UC-26771.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\HMI\\UC-28561.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\HMI\\UC-30371.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\SSTS\\SSTS-6583.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\SSTS\\SSTS-8604.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\SSTS\\SSTS-8692.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\SSTS\\SSTS-8800.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\SSTS\\SSTS-11467.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\SSTS\\SSTS-25957.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\SSTS\\SSTS-26161.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\SSTS\\SSTS-26771.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\SSTS\\SSTS-28561.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\SSTS\\SSTS-30371.docx',\n",
    "    r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\data\\raw_data\\SSTS\\SSTS-31523.docx'\n",
    "\n",
    "]  \n",
    "\n",
    "df = load_files_to_dataframe(file_paths)\n",
    "\n",
    "#df.to_excel('outputs__1.xlsx', index=False)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r'C:\\Users\\HP\\Documents\\GitHub\\atom-compliance-ml\\src\\notebooks\\outputs__1.xlsx')\n",
    "\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "data['UC'] = data['UC'].apply(lemmatize_text)\n",
    "data['SSTS'] = data['SSTS'].apply(lemmatize_text)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "uc_vectors = vectorizer.fit_transform(data['UC'])\n",
    "ssts_vectors = vectorizer.transform(data['SSTS'])\n",
    "\n",
    "similarity_matrix = cosine_similarity(uc_vectors, ssts_vectors)\n",
    "euclidean_dist_matrix = euclidean_distances(uc_vectors, ssts_vectors)\n",
    "\n",
    "max_similarities = similarity_matrix.max(axis=1)\n",
    "mse = np.mean((1 - max_similarities) ** 2)  \n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "seen = set()  \n",
    "\n",
    "def get_differences_and_description(text1, text2):\n",
    "    diff = list(difflib.ndiff(text1.split(), text2.split()))\n",
    "    differences = ' '.join([word for word in diff if word.startswith('-') and word not in seen])\n",
    "    description = ' '.join([word for word in diff if word.startswith('+') and word not in seen])\n",
    "    seen.update(differences.split()) \n",
    "    seen.update(description.split())  \n",
    "    return differences, description\n",
    "\n",
    "report_data = {\n",
    "    \"UC Requirement\": data['UC'],\n",
    "    \"Best SSTS Match\": [data['SSTS'][i] for i in similarity_matrix.argmax(axis=1)],\n",
    "    \"Cosine Similarity\": max_similarities,\n",
    "    \"Differences\": [get_differences_and_description(data['UC'][i], data['SSTS'][j])[0] for i, j in enumerate(similarity_matrix.argmax(axis=1))],\n",
    "    \"Description\": [get_differences_and_description(data['UC'][i], data['SSTS'][j])[1] for i, j in enumerate(similarity_matrix.argmax(axis=1))]\n",
    "}\n",
    "\n",
    "report = pd.DataFrame(report_data)\n",
    "\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_col = pd.DataFrame(similarity_matrix.diagonal())\n",
    "data_col_eu = pd.DataFrame(euclidean_dist_matrix.diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_col.to_csv('data_cos1.csv')\n",
    "data_col_eu.to_csv('data_eu.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
